"""
Phase 1: äº‹ä¾‹æ¤œç´¢ãƒ»ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æœ€é©åŒ–ç‰ˆï¼‰
- Phase 1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§è¨˜äº‹æƒ…å ±ã‚’æŠ½å‡º
- Phase 2: åˆ¥ã®LLMã‚³ãƒ¼ãƒ«ã§ã‚·ãƒ³ãƒ—ãƒ«ã«JSONæ•´å½¢ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å¤§å¹…å‰Šæ¸›ï¼‰
"""
import os
import sys
import time
import json
import traceback
from datetime import datetime, timedelta

from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_tavily import TavilySearch
from langgraph.prebuilt import create_react_agent

# JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (åˆ†æãƒ•ã‚§ãƒ¼ã‚ºã¨å…±æœ‰)
RESEARCH_DATA_PATH = "reports/research_data.json"

def search_and_extract_data(target_year: int = None):
    """
    é€±æ¬¡èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’Webæ¤œç´¢ã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸJSONã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    Phase 1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§éæ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    Phase 2: åˆ¥LLMã‚³ãƒ¼ãƒ«ã§JSONæ•´å½¢ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ï¼‰
    """
    print("\n" + "=" * 60)
    print("ğŸš€ Phase 1: äº‹ä¾‹æ¤œç´¢ã¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’é–‹å§‹")
    print("=" * 60)

    # --- 1. ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª ---
    google_api_key = os.environ.get("GOOGLE_API_KEY")
    tavily_api_key = os.environ.get("TAVILY_API_KEY")

    if not google_api_key or not tavily_api_key:
        print("âŒ ã‚¨ãƒ©ãƒ¼: GOOGLE_API_KEY/TAVILY_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    print("âœ“ APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¾ã—ãŸ")

    # --- 2. LLMã¨ãƒ„ãƒ¼ãƒ«ã®æº–å‚™ ---
    model = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
    )

    search_tool = TavilySearch(
        max_results=10,
        search_depth="advanced",
        include_raw_content=True,
    )
    tools = [search_tool]
    
    # --- 3. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ ---
    agent_executor = create_react_agent(model, tools)
    print("âœ“ ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­å®šã—ã¾ã—ãŸ")

    # --- 4. æ¤œç´¢å¯¾è±¡å¹´ã®è¨­å®šã¨æœŸé–“ã®è¨ˆç®— ---
    today = datetime.now()
    start_date = (today - timedelta(days=7)).strftime("%Y-%m-%d")
    year = target_year or today.year
    
    print(f"ğŸ“… æ¤œç´¢å¯¾è±¡å¹´: {year}")
    print(f"ğŸ—“ï¸ æ¤œç´¢é–‹å§‹æ—¥: {start_date} (éå»1é€±é–“)")

    # --- 5. Phase 1: éæ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---
    search_prompt = f"""
ã‚ãªãŸã¯å„ªç§€ãªãƒªã‚µãƒ¼ãƒã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚Webæ¤œç´¢ã¨æƒ…å ±æŠ½å‡ºã‚’è¡Œã„ã€çµæœã‚’**ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆå½¢å¼**ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

# ğŸ¯ ã‚¿ã‚¹ã‚¯
**éå»1é€±é–“ä»¥å†…ï¼ˆ{start_date}ä»¥é™ï¼‰ã«å…¬é–‹ã•ã‚ŒãŸ**ã‚¹ã‚­ãƒ«ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãƒ»ã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ**ã«é–¢ã™ã‚‹æ¬§ç±³ã®æœ€æ–°è¨˜äº‹ã‚’èª¿æŸ»ã—ã€å„è¨˜äº‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

# ğŸ” èª¿æŸ»å¯¾è±¡ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
- **å¯¾è±¡åœ°åŸŸ**: ç±³å›½ã€è‹±å›½ã€ãƒ‰ã‚¤ãƒ„ã€ãƒ•ãƒ©ãƒ³ã‚¹ã€ã‚ªãƒ©ãƒ³ãƒ€ã€ã‚¹ã‚¦ã‚§ãƒ¼ãƒ‡ãƒ³ã€ã‚¤ã‚¿ãƒªã‚¢ã€ã‚¹ãƒšã‚¤ãƒ³
- **æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ"past week", "last 7 days", "{year}"ï¼‰ã‚’çµ„ã¿åˆã‚ã›ã¦ã€**å¤šæ§˜ãªæ¤œç´¢ã‚’5å›ä»¥ä¸Šå®Ÿè¡Œ**ã—ã¦ãã ã•ã„ã€‚
  - "skill management", "skills management", "talent management", "competency mapping", "skills taxonomy", "workforce upskilling", "reskilling", "digital credentials", "learning experience platform", "skills-based organization", "skills-first hiring", "manufacturing workforce", "factory training"
- **å¿…é ˆ**: æ¤œç´¢çµæœã®URLã«å¯¾ã—ã¦**web_fetch**ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã€è¨˜äº‹æœ¬æ–‡ã‚’èª­ã‚“ã§æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

# ğŸ“„ å‡ºåŠ›å½¢å¼
å„è¨˜äº‹ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’**ç°¡æ½”ãªãƒ†ã‚­ã‚¹ãƒˆå½¢å¼**ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ç›®æ¨™ã¯**10ï½20ä»¶**ã®è¨˜äº‹ã§ã™ã€‚

å„è¨˜äº‹ã¯ä»¥ä¸‹ã®å½¢å¼ã§è¨˜è¼‰ã—ã¦ãã ã•ã„ï¼š

---
## è¨˜äº‹ [ç•ªå·]

**ã‚¿ã‚¤ãƒˆãƒ«**: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«]
**URL**: [æ­£ç¢ºãªè¨˜äº‹URL]
**æƒ…å ±æº**: [ãƒ¡ãƒ‡ã‚£ã‚¢å]
**å…¬é–‹æ—¥**: [YYYY-MM-DDå½¢å¼]
**åœ°åŸŸ**: [å¯¾è±¡åœ°åŸŸ/å›½]
**ã‚«ãƒ†ã‚´ãƒªãƒ¼**: [feature/partnership/case_study/integration/funding/acquisition/pricing/regulation/research/dev_update ã®ã„ãšã‚Œã‹]
**é–¢é€£ä¼æ¥­**: [ä¼æ¥­åã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ãªã‘ã‚Œã°ã€Œãªã—ã€]

**è¦ç´„**:
[3ï½5æ–‡ã®æ—¥æœ¬èªè¦ç´„]

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- [ãƒã‚¤ãƒ³ãƒˆ1]
- [ãƒã‚¤ãƒ³ãƒˆ2]
- [ãƒã‚¤ãƒ³ãƒˆ3]

**ã‚¿ã‚°**: [tag1, tag2, tag3 ãªã©ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š]
**è£½é€ æ¥­é–¢é€£æ€§**: [ã‚ã‚Š/ãªã—]
**é–¢é€£æ€§ç†ç”±**: [ã‚ã‚‹å ´åˆã¯1ï½2æ–‡ã§èª¬æ˜ã€ãªã‘ã‚Œã°ã€Œè©²å½“ãªã—ã€]
**ä¿¡é ¼åº¦**: [0.0ï½1.0ã®æ•°å€¤]

---

# âš ï¸ é‡è¦ãªèª¿æŸ»ãƒ«ãƒ¼ãƒ«
1. **å¿…ãšweb_fetchãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹æœ¬æ–‡ã‚’èª­ã‚€ã“ã¨**
2. ç›®æ¨™ä»¶æ•°ã¯**10ï½20ä»¶**ã®è¨˜äº‹ã‚’åé›†ã™ã‚‹ã“ã¨
3. æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„è¨˜äº‹ã‚’å„ªå…ˆã™ã‚‹ã“ã¨ï¼ˆç‰¹ã«è£½é€ æ¥­é–¢é€£ï¼‰
4. é‡è¤‡è¨˜äº‹ã¯é™¤å¤–ã™ã‚‹ã“ã¨
5. å‡ºåŠ›ã¯ä¸Šè¨˜ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã€è¨˜äº‹ã”ã¨ã«ã€Œ---ã€ã§åŒºåˆ‡ã‚‹ã“ã¨
"""
    
    print("ğŸ” ã‚¹ã‚­ãƒ«ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãƒ»ã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã®æœ€æ–°å‹•å‘èª¿æŸ»ã‚’é–‹å§‹ã—ã¾ã™...")

    # --- 6. Phase 1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œï¼ˆãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼‰ ---
    MAX_RETRIES = 5
    INITIAL_DELAY = 10
    raw_text_output = None

    for attempt in range(MAX_RETRIES):
        try:
            if attempt > 0:
                delay = INITIAL_DELAY * (2 ** (attempt - 1))
                print(f"\nâš ï¸ Quotaè¶…éã®ãŸã‚ã€{delay:.0f}ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™... (è©¦è¡Œå›æ•°: {attempt + 1}/{MAX_RETRIES})")
                time.sleep(delay)

            response = agent_executor.invoke({"messages": [HumanMessage(content=search_prompt)]})
            
            messages = response.get("messages", [])
            if messages and hasattr(messages[-1], "content"):
                raw_text_output = messages[-1].content
                
                # ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã®ç°¡æ˜“æ¤œè¨¼ï¼ˆæœ€ä½é™ã®å†…å®¹ãŒã‚ã‚‹ã‹ï¼‰
                if len(raw_text_output) > 500 and "##" in raw_text_output:
                    print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸã€‚æ–‡å­—æ•°: {len(raw_text_output)}")
                    break
                else:
                    print("\nâš ï¸ å‡ºåŠ›ãŒçŸ­ã™ãã‚‹ã‹å½¢å¼ãŒä¸æ­£ã§ã™ã€‚å†è©¦è¡Œã—ã¾ã™ã€‚")
                    if attempt == MAX_RETRIES - 1:
                        raise ValueError("æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                    continue
            else:
                print("âŒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®å‡ºåŠ›å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                if attempt == MAX_RETRIES - 1:
                    sys.exit(1)
                continue

        except Exception as e:
            error_message = str(e)
            if "429 You exceeded your current quota" in error_message or "ResourceExhausted" in error_message:
                if attempt == MAX_RETRIES - 1:
                    print(f"\nâŒ æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚APIã®å‰²ã‚Šå½“ã¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    traceback.print_exc()
                    sys.exit(1)
                continue
            
            print(f"\nâŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_message}")
            traceback.print_exc()
            sys.exit(1)

    # --- 7. Phase 2: JSONæ•´å½¢ï¼ˆåˆ¥LLMã‚³ãƒ¼ãƒ«ãƒ»ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ï¼‰ ---
    print("\n" + "=" * 60)
    print("ğŸ”„ Phase 2: JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®å¤‰æ›ã‚’é–‹å§‹")
    print("=" * 60)
    
    # JSONæ•´å½¢ç”¨ã®è»½é‡LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå±¥æ­´ãªã—ï¼‰
    formatting_model = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
    )
    
    json_formatting_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã«ã¯ã€è¤‡æ•°ã®è¨˜äº‹æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’ã€æŒ‡å®šã•ã‚ŒãŸJSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦æ•´å½¢ã—ã¦ãã ã•ã„ã€‚

# å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ:
{raw_text_output}

# å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒ:
ä»¥ä¸‹ã®å½¢å¼ã®JSONé…åˆ—ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã‚„èª¬æ˜ã¯ä¸€åˆ‡å«ã‚ãšã€ç´”ç²‹ãªJSONé…åˆ—ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
```json
[
  {{
    "title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
    "url": "æ­£ç¢ºãªè¨˜äº‹ã®URL",
    "source": "æƒ…å ±æºï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢åï¼‰",
    "published_date": "YYYY-MM-DD",
    "region": "å¯¾è±¡åœ°åŸŸ/å›½",
    "category": "feature/partnership/case_study/integration/funding/acquisition/pricing/regulation/research/dev_updateã®ã„ãšã‚Œã‹",
    "related_companies": ["ä¼æ¥­å1", "ä¼æ¥­å2"],
    "summary_japanese": "3ï½5æ–‡ã®æ—¥æœ¬èªè¦ç´„",
    "key_points": ["é‡è¦ãƒã‚¤ãƒ³ãƒˆ1", "é‡è¦ãƒã‚¤ãƒ³ãƒˆ2", "é‡è¦ãƒã‚¤ãƒ³ãƒˆ3"],
    "tags": ["tag1", "tag2", "tag3"],
    "manufacturing_relevance": "ã‚ã‚Š" or "ãªã—",
    "relevance_reason": "é–¢é€£æ€§ãŒã‚ã‚‹å ´åˆã®ç†ç”±ï¼ˆ1ï½2æ–‡ï¼‰",
    "confidence_score": 0.0ã‹ã‚‰1.0ã®é–“ã®æ•°å€¤
  }}
]
```

# é‡è¦äº‹é …:
- å‡ºåŠ›ã¯ä¸Šè¨˜JSONã‚¹ã‚­ãƒ¼ãƒã«å³å¯†ã«å¾“ã†ã“ã¨
- JSONé…åˆ—ã®ã¿ã‚’å‡ºåŠ›ã—ã€å‰å¾Œã«èª¬æ˜æ–‡ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ï¼ˆ```ï¼‰ã‚’å«ã‚ãªã„ã“ã¨
- ã™ã¹ã¦ã®è¨˜äº‹ã‚’é…åˆ—ã«å«ã‚ã‚‹ã“ã¨
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸æ˜ãªå ´åˆã¯å¦¥å½“ãªæ¨æ¸¬å€¤ã¾ãŸã¯ç©ºã®å€¤ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
"""

    for attempt in range(MAX_RETRIES):
        try:
            if attempt > 0:
                delay = INITIAL_DELAY * (2 ** (attempt - 1))
                print(f"\nâš ï¸ Quotaè¶…éã®ãŸã‚ã€{delay:.0f}ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™... (è©¦è¡Œå›æ•°: {attempt + 1}/{MAX_RETRIES})")
                time.sleep(delay)

            formatting_response = formatting_model.invoke([HumanMessage(content=json_formatting_prompt)])
            json_output = formatting_response.content
            
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤
            json_output = json_output.strip()
            if json_output.startswith("```json"):
                json_output = json_output[7:]
            if json_output.startswith("```"):
                json_output = json_output[3:]
            if json_output.endswith("```"):
                json_output = json_output[:-3]
            json_output = json_output.strip()
            
            # JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
            parsed_data = json.loads(json_output)
            
            if isinstance(parsed_data, list) and parsed_data:
                print(f"âœ… JSONãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«å¤‰æ›ã—ã¾ã—ãŸã€‚è¨˜äº‹æ•°: {len(parsed_data)}ä»¶")
                break
            else:
                raise ValueError("JSONã®å½¢å¼ãŒæœŸå¾…é€šã‚Šï¼ˆéç©ºã®é…åˆ—ï¼‰ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        except json.JSONDecodeError as e:
            print(f"\nâŒ JSONå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            if attempt == MAX_RETRIES - 1:
                print("ç”Ÿã®JSONå‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰:")
                print(json_output[:1000])  # æœ€åˆã®1000æ–‡å­—ã®ã¿è¡¨ç¤º
                sys.exit(1)
            continue
            
        except Exception as e:
            error_message = str(e)
            if "429 You exceeded your current quota" in error_message or "ResourceExhausted" in error_message:
                if attempt == MAX_RETRIES - 1:
                    print(f"\nâŒ æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚APIã®å‰²ã‚Šå½“ã¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    traceback.print_exc()
                    sys.exit(1)
                continue
            
            print(f"\nâŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_message}")
            traceback.print_exc()
            if attempt == MAX_RETRIES - 1:
                sys.exit(1)
            continue

    # --- 8. JSONãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ ---
    os.makedirs("reports", exist_ok=True)
    
    try:
        with open(RESEARCH_DATA_PATH, "w", encoding="utf-8") as f:
            f.write(json.dumps(parsed_data, indent=2, ensure_ascii=False))

        print("\n" + "=" * 60)
        print("âœ“ ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
        print(f"ğŸ’¾ ä¿å­˜å…ˆ: {RESEARCH_DATA_PATH}")
        print(f"ğŸ“Š è¨˜äº‹æ•°: {len(parsed_data)}ä»¶")
        print("=" * 60 + "\n")
        
        return RESEARCH_DATA_PATH

    except Exception as e:
        print(f"\nâŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    year_arg = None
    if len(sys.argv) > 1:
        try:
            year_arg = int(sys.argv[1])
        except ValueError:
            print("âš ï¸ å¹´æŒ‡å®šãŒä¸æ­£ã§ã™ã€‚æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ä¾‹: python research_searcher.py 2026")

    search_and_extract_data(target_year=year_arg)